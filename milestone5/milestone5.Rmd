---
title: 'Milestone #5 - 6'
author: "Niel Schrage"
date: "4/8/2020"
output: bookdown::pdf_document2
bibliography: [replicationbib.bib]
biblio-style: "apalike"
link-citations: false
toc: false
nocite: |
  @Enos16, @King06, @King00, @Enos14, @Fossett89, @Kinder96, @Craig18, @Dinesen15

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# loading libraries

library(tidyverse)
library(bookdown)
library(tinytex)
library(gt)
library(gtsummary)
library(stargazer)
library(knitr)
library(styler)
library(bookdown)

options(tinytex.verbose = TRUE)


pdf_document2()
```

# Things I still have to do 
- beautiful graphic + caption
- get at least one table in the pdf (plus include screenshot... )
- replication statement
- proposed extension


# Introduction

This project is my attempt at replicating a published paper by a respected academic. It is the final for [Gov 1006](https://www.davidkane.info/files/gov_1006_spring_2020.html), a class that has taught me a seemingly endless amount about data science, R, and life's most pressing questions. All analysis for this paper is available in my repository.^[https://github.com/nschrage/replication_2] The paper I have selected is by [Ryan D. Enos](http://ryandenos.com/) entitled ["What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior."](https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12156) Thank you to Professor Enos for providing easily accessible [replication data](http://dvn.iq.harvard.edu/dvn/dv/ajps) through the [Harvard Dataverse](https://dataverse.harvard.edu/).

# Overview of Replication Paper

In the paper “What the Demolition of Public Housing Teaches Us about the Impact of Racial Threat on Political Behavior”, Ryan Enos studies the impact that an exogenous demographic shift has on voting turnout and results. This paper seeks to answer the overarching question: how much the context in which a certain person lives affects their political behavior? 

While this has long been a question political scientists have been interested in exploring, there are usually a number of obstacles to conducting a thorough investigation. Enos highlights shortcomings in data, identification, and theory as historical limitations to contextual racial threat examinations. This variety of potential endogenous confounding factors that have historically made academic consensus on research and conclusions from context based racial threat studies hard to find.

In the early 2000s, public housing reconstruction in Chicago caused mass displacement 25,000 among African Americans. Enos takes advantage of this unique situation in Chicago to study racial threat and context. By relying on the external nature of these demolitions -- the deciding factors about which projects would be demolished were based on algorithms outside of individual residents control -- Enos looks at the effect of removing African American neighbors on white voting turnout in Chicago. **The key assumption in this article is that the choice of units designated for demolition is uncorrelated with the difference in changes in turnout for white and African American voters**

Enos describes how the demolitions can be thought of as a quasi -experiment, “ The treatment is the demolition, and the outcome is the change in white political participation and support for conservative candidates.” 

Enos utilized four different data sources to run this study: voting information consisting of an augmented 2004 Illinois voter file updated with 2000 and 2010 census data, location data between voters and their distance from each demolished housing project, edge data covering the exact distance between each voter and the edge of a housing project, and lastly property records for all Chicago voters.  

These data sources provide many advantages previously unavailable to studies of racial threat: individual voter data avoids the ecological assumptions that usually plague aggregate/sampling data, and location data is helpful because it allows for testing of of a variety of definitions.  

Enos had 3 hypothesis:

- H1 (Racial Threat and Turnout): After the de- molition of the projects, turnout should decline for white voters close to the projects relative to the rest of the city.

- H2 (Proximity and Size): The salience of a group is a strong predictor of intergroup attitudes (Brewer and Miller 1984). Psychologists have empirically demonstrated the intuitive finding that salience can be a function of the size and “immediacy” of an object (Latane 1981; Latane and L’Herrou 1996; Latane et al. 1995; Lewenstein, Nowak, and Latane 1992; Latane and Wolf 1981). This leads me to expect a “dose effect,” whereby the treatment should vary with the size and proximity of the treatment. Operationally, the treatment effect should decline as the white voters are farther away from a project and as the population of a project represents a smaller portion of the local outgroup population. 

- H3 (Racial Threat and Vote Choice): After the demolition of the projects, white voters close to the former projects should experience a decline in racially conservative voting relative to the rest of the city.

Enos tested the difference-in-differences in voter turnout between sets of voters before and after the demolition. The results suggest that racial threat is highly context specific and that the strength of the effect is inversely correlated with distance from the project and directly correlated with the size of the outgroup. These findings strongly suggest that racial threat occurs because of attitude change rather than selection.

# Replication Statement

* **6** A clear statement about what aspects of the paper you were able to replicate and which parts, if any, you were not able to replicate.

# Proposed Extension

* **6** 500 words about your proposed extension. You do not have to have done the extension yet. (That comes next week.) But it is time to start thinking about what your contribution to human knowledge will be. You seek admission to the School of Athens. What do you have to offer us?

missing values. 

more recent data (?) -- that could be interesting. 

joining other data sets with what I have (?)

need to just to more research in general about this topic. 

less crazy --> making some new cooler visuals (this is appealing).

use the bayesian stan glm thing to see if I  get different results. 

are the results as strong as he suggests. 


# Milestone #5 Beautiful Graphic

* A beautiful graphic which uses this data. (May be similar to or different from a graphic in the original paper.) Use King et al (2000) for inspiration. This is the portion of the submission which will be graded most harshly. Make sure that you include a thorough caption.

**how to include a caption**

```{r graphic, echo=FALSE}

```






# Appendix

```{r setting up replication, echo = FALSE, message=FALSE}

# setting up global values

# this package is about statistical estimates.
library(ei)
# package helpful for matching treated and control groups with similar covariate
# distributions.
library(MatchIt)
# package for producing simple weighted statistics
library(weights)
# simple bootstrapping -- didn't know this existed.
library(simpleboot)
# helpful statistics package, especially for modeling
library(Zelig)
# package that helps format latex objects side by side
library(apsrtable)

### master graphic parameters for graphics
ylims <- c(-.35, .1)
ylims.2 <- c(-.45, .1)
xlims <- c(.5, 11)
dists <- seq(from = 1000, to = 100, by = -100) ### DELETE THIS LATER
xs <- seq(1:length(dists))
ys <- seq(from = -.35, to = .1, by = .05)
ys.lab <- c("-0.35", "-0.30", "-0.25", "-0.20", "-0.15", "-0.10", "-0.05", "0.00", "0.05", "0.10")
ys.2 <- seq(from = -.45, to = .1, by = .05)
ys.lab.2 <- c("-0.45", "-0.40", "-0.35", "-0.30", "-0.25", "-0.20", "-0.15", "-0.10", "-0.05", "0.00", "0.05", "0.10")

offsets <- .15
text.offsets <- .025
cex.axis <- .9
cex.N <- .7
top.text.adj <- c(1.3, 1.3) ## offsets on labels to reduce crowding
bottom.text.adj <- c(-.15, -.85)
point.size <- 2
line.offset <- .0175
```

## Figure #1

```{r figure 1, echo = FALSE}

# how to display results.

# how to only display graph 1, not the appendix stuff

# need to spend more time going through here and figuring out what does what.
# should I just turn in milestone #5 before milestone #6 or should I just go along and do both at the same time.

## load data

# IMPORTANT --> FOR SOME REASON I NEED TO PUT IN THE FULL FILE PATH IN ORDER FOR THIS TO WORK... DOESN'T THIS MAKE IT HARDER FOR MY WORK TO BE REPLICATED? WHAT SHOULD I DO HERE? AM GOING TO PROCEEDE SO THAT I CAN GET STUFF DOWN.

# ALSO WHY DO THE GRAPHS APPEAR IN SEPARATE PDFS, HOW CAN I GET THEM TO APPEAR WITHIN THIS MARKDOWN DOCUMENT?

wtreat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.effect.mean.boot.csv")
wtreat.lower <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.effect.conf.boot.lower.csv")
wtreat.upper <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.effect.conf.boot.upper.csv")
Nwtreat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.treat.N.csv")
btreat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.effect.mean.boot.csv")
btreat.lower <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.effect.conf.boot.lower.csv")
btreat.upper <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.effect.conf.boot.upper.csv")
Nbtreat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/black.treat.N.csv")

## letters for marking graphs, one is not used
use.letters <- c("a", "b", "c", "d", "e", "f", "skip", "g", "h")

## cycle through each line of data, each of which are groups defined by diferent namepcts
for (i in 1:nrow(wtreat)) { ## turning into matrices helps below with segment function
  use.wtreat <- as.matrix(wtreat[i, ])
  use.wlower <- as.matrix(wtreat.lower[i, ])
  use.wupper <- as.matrix(wtreat.upper[i, ])
  use.Nwtreat <- as.matrix(Nwtreat[i, ])

  use.btreat <- as.matrix(btreat[i, ])
  use.blower <- as.matrix(btreat.lower[i, ])
  use.bupper <- as.matrix(btreat.upper[i, ])
  use.Nbtreat <- as.matrix(Nbtreat[i, ])

  # how to just get figure_1.pdf to display
  # also how to get the pdf to display in my document?

  ## name graphs
  if (i == 7) {
    pdf("Figure_1.pdf")
  }
  else {
    pdf(paste("Figure_A1", use.letters[i], ".pdf", sep = ""))
  }
  par(las = 1)
  par(mar = c(5.1, 4.1, .5, .5))
  plot(xs, use.wtreat,
    ylim = ylims,
    xlim = xlims,
    type = "n",
    ylab = "Treatment Effect",
    xlab = "Treated Group Distance from Projects",
    xaxt = "n",
    yaxt = "n.csv"
  )
  abline(h = 0, lty = 2)

  ### draw lines first because I want them to be covered by points
  #### create spaces in lines using the offset (this allows the N to be displayed with the text() function)
  ## black lines are offset to the left, white lines to the right
  segments(
    x0 = xs[1:2] + offsets, x1 = xs[1:2] + offsets, ## only do it for low N blacks because otherwise lines look funny
    y0 = use.btreat[, 1:2], y1 = use.blower[, 1:2]
  )
  segments(
    x0 = xs[1:2] + offsets, x1 = xs[1:2] + offsets,
    y0 = use.btreat[, 1:2] + line.offset, y1 = use.bupper[, 1:2]
  )
  ## now the others
  segments(
    x0 = xs[3:10] + offsets, x1 = xs[3:10] + offsets,
    y0 = use.blower[, 3:10], y1 = use.bupper[, 3:10]
  )

  segments(
    x0 = xs - offsets, x1 = xs - offsets, ## bottomlines
    y0 = use.wtreat - line.offset, y1 = use.wlower
  )
  segments(
    x0 = xs - offsets, x1 = xs - offsets, ## toplines
    y0 = use.wtreat, y1 = use.wupper
  )


  ## points and N descriptions
  points(xs - offsets, use.wtreat,
    cex = point.size,
    pch = 21,
    bg = "white",
    col = "black"
  )
  text(xs - offsets, use.wtreat,
    paste("(", use.Nwtreat, ")", sep = ""),
    cex = cex.N,
    # adj = top.text.adj
    pos = 1
  )

  points(xs + offsets, use.btreat,
    pch = 16,
    cex = point.size
  )
  text(xs + offsets, use.btreat,
    paste("(", use.Nbtreat, ")", sep = ""),
    cex = cex.N,
    # adj = bottom.text.adj
    pos = 3
  )

  axis(
    side = 1,
    at = xs,
    label = seq(100, 1000, 100),
    cex.axis = cex.axis
  )
  axis(
    side = 2,
    at = ys,
    label = ys.lab,
    cex.axis = cex.axis
  )

  dev.off()
}

pdf("Figure_1.pdf")
```

## Figure #2 and #3

```{r figures 2-3, echo=FALSE}

## this cycles thorugh a bunch of dataframes, each of which is needed for a different graph
for (figure in c("white.basic.main", "white.demo.main", "white.demo.property", "white.demo.localrace", "blackmain", "blackcensus")) {
  if (figure == "white.basic.main") {
    ## this group is different than the rest because the second set is not actually a diff in diff, but calling it "diffs" for consistency
    treat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.basic.csv")
    treat.2 <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.basic.property.csv")
    fig.nums <- c("A3", "A4") ## figure names
    pchs <- c(17, 17) ## point types
  }
  if (figure == "white.demo.main") {
    treat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.csv")
    diffs <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.diffs.csv")
    fig.nums <- c("2", "A5")
    pchs <- c(17, 22)
  }
  if (figure == "white.demo.property") {
    treat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.property.csv")
    diffs <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.diffs.property.csv")
    fig.nums <- c("A6", "A7")
    pchs <- c(17, 22)
  }
  if (figure == "white.demo.localrace") {
    treat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.localrace.csv")
    diffs <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.nondemolished.diffs.localrace.csv")
    fig.nums <- c("A8", "A9")
    pchs <- c(17, 22)
  }
  if (figure == "blackmain") {
    treat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.property.csv")
    diffs <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.diffs.property.csv")
    fig.nums <- c("3", "A12")
    pchs <- c(17, 21)
  }
  if (figure == "blackcensus") {
    treat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.csv")
    diffs <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/white.match.black.diffs.csv")
    fig.nums <- c("A10", "A11")
    pchs <- c(17, 21)
  }


  ## define axis for different graphs
  if (figure %in% c("white.basic.main", "white.demo.main", "blackmain")) {
    use.ylims <- ylims
    use.ys.lab <- ys.lab
    use.ys <- ys
  }
  else {
    use.ylims <- ylims.2
    use.ys.lab <- ys.lab.2
    use.ys <- ys.2
  }

  ## go through pairs for each pair of dataframe
  for (i in 1:2) {
    if (i == 1) {
      use.treat <- treat$coefficient
      clower <- use.treat - (1.96 * treat$stdev)
      cupper <- use.treat + (1.96 * treat$stdev)
      use.N.treat <- treat$N.treatment + treat$N.control
    }
    if (i == 2 & figure != "white.basic.main") {
      use.treat <- diffs$mean.diff
      clower <- diffs$low.ci
      cupper <- diffs$high.ci
      use.N.treat <- diffs$N
    }
    if (i == 2 & figure == "white.basic.main") { ## white.basic.main figures have slightly different structure
      use.treat <- treat.2$coefficient
      clower <- use.treat - (1.96 * treat.2$stdev)
      cupper <- use.treat + (1.96 * treat.2$stdev)
      use.N.treat <- treat.2$N.treatment + treat.2$N.control
    }
    if (figure %in% c("white.demo.main", "blackmain") & i == 1) {
      pdf(paste("Figure_", fig.nums[i], ".pdf", sep = ""))
    }
    else {
      pdf(paste("Figure_", fig.nums[i], ".pdf", sep = ""))
    }
    par(las = 1)
    par(mar = c(5.1, 4.1, .5, .5))
    plot(xs, use.treat,
      ylim = use.ylims,
      xlim = xlims,
      type = "n",
      ylab = "Treatment Effect",
      xlab = "Treated Group Distance from Projects",
      xaxt = "n",
      yaxt = "n"
    )
    abline(h = 0, lty = 2)

    segments(
      x0 = xs, x1 = xs,
      y0 = use.treat + line.offset, y1 = cupper
    )
    segments(
      x0 = xs, x1 = xs,
      y0 = use.treat, y1 = clower
    )

    ### Treatment Effects
    points(xs, use.treat,
      pch = pchs[i],
      cex = point.size,
      bg = "white",
      col = "black"
    )
    text(xs, use.treat,
      paste("(", use.N.treat, ")", sep = ""),
      cex = cex.N,
      pos = 3
    )
    axis(
      side = 1,
      at = xs,
      label = seq(100, 1000, 100),
      cex.axis = cex.axis
    )
    axis(
      side = 2,
      at = use.ys,
      label = use.ys.lab,
      cex.axis = cex.axis
    )

    dev.off()
  }
}
```

## Figure #4

```{r figure 4, echo = FALSE}

## write out regression to latex table

# THIS IS SOMETHING THAT DOESN'T WORK, BUT IT IS SOMETHING THAT I CAN WRITE ABOUT FOR ONE OF THE QUESTIONS ON THE MILESTONE. FOR FIGURE 4, THE TABLE WITH THE REGRESSION WAS UNABLE TO LOAD, UPON FURTHER ANALYSIS, IT LOOKS LIKE THE .RDA FILE DOES NOT EXIST IN THE DATA VERSE FOLDER. TO MAKE SURE, I ALSO CHECKED ONLINE AND THIS WAS ALSO THE CASE, NOT SURE WHY THIS IS OR IF IT STOPS US FROM GETTING SOME OF THE OTHER DATA/FIGURES.

# load('~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/out.reg.predictions.rda') ##load saved model
# out.model = apsrtable(out.reg.predictions,
# 	coef.names = c( 'Intercept','log(distance)','log(percent of local black population)','2000 turnout'),
# 	digits = 3
# 	)
# writeLines(out.model,
# 	'Table_1.tex')

distdat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/predicted.results.distance.vary.context.csv")
areadat <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/predicted.results.area.vary.context.csv")

## new ylims for these graphs
ylims.predict <- c(.6, .75)

datas <- list(distdat, areadat) ## put data in a list to cycle through
## parameters to be used in graphs below
xs <- list(seq(from = 10, to = 2000, by = 10), seq(from = 45000, to = 1004000, by = 4800) / 1000)
use.letters <- c("a", "b")
xlabs <- c("Distance from Project", "Percent of Local Black Population in Demolished Project")
ylabs <- c(expression(Pr(vote[2004])), "")
vlines <- list(seq(from = 0, to = 2000, by = 200), seq(from = 0, to = 1000, by = 100))
axis.labs <- list(
  as.character(seq(from = 0, to = 2000, by = 200)),
  as.character(c("0", "10%", "20%", "30%", "40%", "50%", "60%", "70%", "80%", "90%", "100%"))
)

for (i in 1:2) {
  colnames(datas[[i]]) <- c("mean", "sd", "50%", "2.5%", "97.5%") ## saving renames columns, so name back

  pdf(paste("Figure_4", use.letters[i], ".pdf", sep = ""))
  par(las = 1)
  par(mar = c(5.1, 4.1, .5, .5))
  plot(xs[[i]], datas[[i]][, "mean"],
    type = "l",
    xlab = xlabs[i],
    ylab = ylabs[i],
    ylim = ylims.predict,
    xaxt = "n",
    cex.axis = cex.axis,
    lwd = 4
  )
  ## put horizontal and vertical lines on plots
  abline(
    h = seq(from = min(ylims.predict), to = max(ylims.predict), by = .025),
    lty = 2,
    col = "gray",
    lwd = 1
  )
  abline(
    v = vlines[[i]],
    lty = 2,
    col = "gray",
    lwd = 1
  )
  lines(xs[[i]], datas[[i]][, "2.5%"],
    lty = 3,
    lwd = 2.5
  )
  lines(xs[[i]], datas[[i]][, "97.5%"],
    lty = 3,
    lwd = 2.5
  )
  axis(
    side = 1,
    at = vlines[[i]],
    labels = axis.labs[[i]],
    cex.axis = cex.axis
  )

  dev.off()
}
```

## Figure #5 and #6

```{r figures 5-6, echo = FALSE}

pres.elections <- c("dole_pct_ei", "bush2000_pct_ei", "bush2004_pct_ei", "mccain_pct_ei")
obama.elections <- c("obama_sen_primary_pct_ei", "keyes_pct_ei", "obama_pres_primary_pct_ei")

dists <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/distance.vote.differences.csv")
demos <- read.csv("~/Desktop/Gov_1006_Projects/replication_2/dataverse_files/demolished.vote.differences.csv")


graphs <- c("5a", "5b", "6")

for (i in graphs) {
  if (i == "5a") {
    dat <- dists
  }
  else {
    dat <- demos
  }

  if (i %in% c("5a", "5b")) {
    xlims <- c(.75, 4.25)
    ylims <- c(-.1, .2)
  }
  else {
    xlims <- c(.75, 3.25)
    ylims <- c(-.1, .25)
  }

  ## recode Keyes to Obama general for presentation purposes
  dat[dat$election == "keyes_pct_ei", "x.mean"] <- 1 - dat[dat$election == "keyes_pct_ei", "x.mean"]
  dat[dat$election == "keyes_pct_ei", "y.mean"] <- 1 - dat[dat$election == "keyes_pct_ei", "y.mean"]
  dat[dat$election == "keyes_pct_ei", "diff"] <- dat[dat$election == "keyes_pct_ei", "y.mean"] - dat[dat$election == "keyes_pct_ei", "x.mean"]

  pdf(paste("Figure_", i, ".pdf", sep = ""),
    width = 7, height = 8
  )
  par(las = 1)
  par(mar = c(5.1, 4.1, .5, 1.5))
  plot(seq(1:4),
    rep(1, 4),
    ylim = ylims,
    xlim = xlims,
    type = "n",
    xaxt = "n",
    yaxt = "n",
    xlab = "Election",
    ylab = ifelse(i == "5b", "", "Treatment Effect")
  )
  abline(h = 0, lty = 2)

  if (i %in% c("5a", "5b")) {
    segments(
      x0 = seq(1:4) - offsets,
      x1 = seq(1:4) - offsets,
      y0 = dat[dat$group == "white" & dat$election %in% pres.elections, "diff"] - (1.96 * dat[dat$group == "white" & dat$election %in% pres.elections, "sd"]),
      y1 = dat[dat$group == "white" & dat$election %in% pres.elections, "diff"] + (1.96 * dat[dat$group == "white" & dat$election %in% pres.elections, "sd"])
    )
    points(seq(1:4) - offsets,
      dat[dat$group == "white" & dat$election %in% pres.elections, "diff"],
      pch = 21,
      bg = "white",
      col = "black",
      cex = 2
    )
    segments(
      x0 = seq(1:4) + offsets,
      x1 = seq(1:4) + offsets,
      y0 = dat[dat$group == "black" & dat$election %in% pres.elections, "diff"] - (1.96 * dat[dat$group == "black" & dat$election %in% pres.elections, "sd"]),
      y1 = dat[dat$group == "black" & dat$election %in% pres.elections, "diff"] + (1.96 * dat[dat$group == "black" & dat$election %in% pres.elections, "sd"])
    )
    points(seq(1:4) + offsets,
      dat[dat$group == "black" & dat$election %in% pres.elections, "diff"],
      pch = 16,
      cex = 2
    )
    axis(
      side = 1, at = seq(1:4),
      c("1996", "2000", "2004", "2008"),
      tick = F,
      cex.axis = cex.axis
    )
  }
  else {
    segments(
      x0 = seq(1:3) - offsets,
      x1 = seq(1:3) - offsets,
      y0 = dat[dat$group == "white" & dat$election %in% obama.elections, "diff"] - (1.96 * dat[dat$group == "white" & dat$election %in% obama.elections, "sd"]),
      y1 = dat[dat$group == "white" & dat$election %in% obama.elections, "diff"] + (1.96 * dat[dat$group == "white" & dat$election %in% obama.elections, "sd"])
    )
    points(seq(1:3) - offsets,
      dat[dat$group == "white" & dat$election %in% obama.elections, "diff"],
      pch = 21,
      bg = "white",
      col = "black",
      cex = 2
    )
    segments(
      x0 = seq(1:3) + offsets,
      x1 = seq(1:3) + offsets,
      y0 = dat[dat$group == "black" & dat$election %in% obama.elections, "diff"] - (1.96 * dat[dat$group == "black" & dat$election %in% obama.elections, "sd"]),
      y1 = dat[dat$group == "black" & dat$election %in% obama.elections, "diff"] + (1.96 * dat[dat$group == "black" & dat$election %in% obama.elections, "sd"])
    )
    points(seq(1:3) + offsets,
      dat[dat$group == "black" & dat$election %in% obama.elections, "diff"],
      pch = 16,
      cex = 2
    )
    axis(
      side = 1, at = seq(1:3),
      c("2004 \n Senate Primary", "2004 \n Senate General", "2008 \n President Primary"),
      tick = F,
      cex.axis = cex.axis
    )
  }
  axis(
    side = 2,
    at = seq(from = -.1, to = .3, by = .05),
    label = c("-0.10", "-0.05", "0.00", "0.05", "0.10", "0.15", "0.20", "0.25", "0.30"),
    cex.axis = cex.axis
  )
  dev.off()
}
```


* Is it written in Base R or in tidyverse. 

* Do I have to reach out to Prof Enos. 

* An Appendix which include a replication of at least one of the tables from your paper. (It can be a simple summary table.) Also, take a screen shot of the original table and include that image in your Appendix. We want to see how closely your results match the original paper’s.

* **6** As with other aspects of this project, the exact requirements will vary across students, depending on the complexity of your replication paper. If you paper only has 3 or 4 tables, we expect you to replicate it all. If it has 50 tables, we do not expect that. Use your best judgment and talk with us. You must replicate any result which you plan to use as the base of your extension.





**how to include a screenshot in the pdf?**

# Bibliography

* A bibliography with at least five references, one of which will be the article you are replicating for your extension.




